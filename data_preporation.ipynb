{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9767dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import random\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa814d29",
   "metadata": {},
   "source": [
    "## Prepare data for first model (clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7f1c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/data_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb788fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!mkdir data/data_clf/A1 data/data_clf/A2 data/data_clf/A3 data/data_clf/A4 data/data_clf/A5 data/data_clf/A6 data/data_clf/A7 data/data_clf/A8 data/data_clf/A9 data/data_clf/A10 data/data_clf/A11 data/data_clf/A12 data/data_clf/A13 data/data_clf/A14 data/data_clf/A15 data/data_clf/A16 data/data_clf/A17 data/data_clf/A18 data/data_clf/A19 data/data_clf/A20'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"!mkdir\"\n",
    "\n",
    "for i in range(1, 21):\n",
    "    command += f\" data/data_clf/A{i}\"\n",
    "command # prepared a command to create needed directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66851c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/data_clf/A1 data/data_clf/A2 data/data_clf/A3 data/data_clf/A4 data/data_clf/A5 data/data_clf/A6 data/data_clf/A7 data/data_clf/A8 data/data_clf/A9 data/data_clf/A10 data/data_clf/A11 data/data_clf/A12 data/data_clf/A13 data/data_clf/A14 data/data_clf/A15 data/data_clf/A16 data/data_clf/A17 data/data_clf/A18 data/data_clf/A19 data/data_clf/A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddac3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_core_path = \"data/data_core/Annotations/Horizontal Bounding Boxes/\"\n",
    "images_core_path = \"data/data_core/JPEGImages/\"\n",
    "\n",
    "data_target_path = \"data/data_clf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfae4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = np.array(os.listdir(labels_core_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b0c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from the data_core dir and save it in the target dir (for each class there is a dir)\n",
    "for xml_path in labels_dir:\n",
    "\n",
    "    tree = ET.parse(os.path.join(labels_core_path, xml_path))\n",
    "    \n",
    "    root = tree.getroot()    \n",
    "    \n",
    "    image = cv.imread(os.path.join(images_core_path, xml_path[:-3] + \"jpg\"))\n",
    "    \n",
    "    count = 0\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.find(\"name\").text\n",
    "        \n",
    "        bb = obj.find(\"bndbox\")\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = (int(bb.find(\"xmin\").text),\n",
    "                                  int(bb.find(\"ymin\").text),\n",
    "                                  int(bb.find(\"xmax\").text),\n",
    "                                  int(bb.find(\"ymax\").text))\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        cv.imwrite(os.path.join(data_target_path, name, xml_path[:-4] + \"_\" + str(count) + \".jpg\"), image[ymin:ymax, xmin:xmax])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e59ee4",
   "metadata": {},
   "source": [
    "## Prepare data for Yolo models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9564fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/data_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34dac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/data_yolo/images data/data_yolo/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfacb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all directories for yolo (appropriate structure)\n",
    "!mkdir data/data_yolo/images/val data/data_yolo/images/train data/data_yolo/labels/val data/data_yolo/labels/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd7b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file with data configs\n",
    "\n",
    "config_path = \"data/data_yolo/config.yaml\"\n",
    "config = \"\"\"path: data/data_yolo\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "names: \n",
    "  \n",
    "  0: A1\n",
    "  1: A2\n",
    "  2: A3\n",
    "  3: A4\n",
    "  4: A5\n",
    "  5: A6\n",
    "  6: A7\n",
    "  7: A8\n",
    "  8: A9\n",
    "  9: A10\n",
    "  10: A11\n",
    "  11: A12\n",
    "  12: A13\n",
    "  13: A14\n",
    "  14: A15\n",
    "  15: A16\n",
    "  16: A17\n",
    "  17: A18\n",
    "  18: A19\n",
    "  19: A20\n",
    "  \"\"\"\n",
    "file = open(config_path, \"w\")\n",
    "file.write(config)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3193ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b0c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1787.xml', '386.xml', '2180.xml', ..., '1170.xml', '1434.xml',\n",
       "       '133.xml'], dtype='<U8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0d4216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index = int(0.7 * len(labels_dir))\n",
    "split_index # make train validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fa7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_target_dir = \"data/data_yolo/images/train/\"\n",
    "val_images_target_dir = \"data/data_yolo/images/val\"\n",
    "\n",
    "train_labels_target_dir = \"data/data_yolo/labels/train/\"\n",
    "val_labels_target_dir = \"data/data_yolo/labels/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d62e2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(target_images_path, target_labels_path, image_name, image, text, hor_flip=True, ver_flip=True):\n",
    "    \"\"\"\n",
    "    function for data augmentation:\n",
    "    flip images horizontally and vertically\n",
    "    and saves them into target dirs with appropriate labels\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    label = np.array([list(map(float, i.split())) for i in text.split(\"\\n\")])\n",
    "    \n",
    "\n",
    "    if hor_flip:\n",
    "        cv.imwrite(os.path.join(target_images_path, image_name + \"hor\" + \".jpg\"), image[:, ::-1])\n",
    "        \n",
    "        hor_label = label.copy()\n",
    "        hor_label[:, 1] = 1 - hor_label[:, 1]\n",
    "        \n",
    "        text = \"\\n\".join([f\"{int(row[0])} {row[1]} {row[2]} {row[3]} {row[4]}\" for row in hor_label])\n",
    "        with open(os.path.join(target_labels_path, image_name + \"hor\" + \".txt\"), \"w\") as file:\n",
    "            file.write(text)\n",
    "    \n",
    "    if ver_flip:\n",
    "        cv.imwrite(os.path.join(target_images_path, image_name + \"ver\" + \".jpg\"), image[::-1, :])\n",
    "        \n",
    "        ver_label = label.copy()\n",
    "        ver_label[:, 2] = 1 - ver_label[:, 2]\n",
    "        \n",
    "        text = \"\\n\".join([f\"{int(row[0])} {row[1]} {row[2]} {row[3]} {row[4]}\" for row in ver_label])\n",
    "        with open(os.path.join(target_labels_path, image_name + \"ver\" + \".txt\"), \"w\") as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b395bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train data for Yolo models\n",
    "\n",
    "for xml_path in labels_dir[:split_index]:\n",
    "\n",
    "    tree = ET.parse(os.path.join(labels_core_path, xml_path))\n",
    "    \n",
    "    root = tree.getroot()    \n",
    "    \n",
    "    image = cv.imread(os.path.join(images_core_path, xml_path[:-3] + \"jpg\"))\n",
    "    image_width, image_height, _ = image.shape\n",
    "    \n",
    "    cv.imwrite(os.path.join(train_images_target_dir, xml_path[:-3] + \"jpg\"), image) # save an image\n",
    "    \n",
    "    text = \"\"\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = int(obj.find(\"name\").text[1:]) - 1\n",
    "        \n",
    "        bb = obj.find(\"bndbox\")\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = (int(bb.find(\"xmin\").text),\n",
    "                                  int(bb.find(\"ymin\").text),\n",
    "                                  int(bb.find(\"xmax\").text),\n",
    "                                  int(bb.find(\"ymax\").text))\n",
    "        \n",
    "        xcenter, ycenter, width, height = ((xmin + xmax) / 2,\n",
    "                                           (ymin + ymax) / 2,\n",
    "                                           (xmax - xmin) / 2,\n",
    "                                           (ymax - ymin) / 2)\n",
    "        \n",
    "        text += f\"{name} {xcenter / image_width} {ycenter / image_height} {width / image_width} {height / image_height}\\n\"\n",
    "    \n",
    "    augment(train_images_target_dir, train_labels_target_dir, xml_path[:-4], image, text.strip()) # augment data\n",
    "    \n",
    "    with open(os.path.join(train_labels_target_dir, xml_path[:-3] + \"txt\"), \"w\") as file: # save label for the original image\n",
    "        file.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd62dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare val data for Yolo models\n",
    "\n",
    "for xml_path in labels_dir[split_index:]:\n",
    "\n",
    "    tree = ET.parse(os.path.join(labels_core_path, xml_path))\n",
    "    \n",
    "    root = tree.getroot()    \n",
    "    \n",
    "    image = cv.imread(os.path.join(images_core_path, xml_path[:-3] + \"jpg\"))\n",
    "    image_width, image_height, _ = image.shape\n",
    "    \n",
    "    cv.imwrite(os.path.join(val_images_target_dir, xml_path[:-3] + \"jpg\"), image) # save an image\n",
    "    \n",
    "    text = \"\"\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = int(obj.find(\"name\").text[1:]) - 1\n",
    "        \n",
    "        bb = obj.find(\"bndbox\")\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = (int(bb.find(\"xmin\").text),\n",
    "                                  int(bb.find(\"ymin\").text),\n",
    "                                  int(bb.find(\"xmax\").text),\n",
    "                                  int(bb.find(\"ymax\").text))\n",
    "        \n",
    "        xcenter, ycenter, width, height = ((xmin + xmax) / 2,\n",
    "                                           (ymin + ymax) / 2,\n",
    "                                           (xmax - xmin) / 2,\n",
    "                                           (ymax - ymin) / 2)\n",
    "        \n",
    "        text += f\"{name} {xcenter / image_width} {ycenter / image_height} {width / image_width} {height / image_height}\\n\"\n",
    "    \n",
    "    with open(os.path.join(val_labels_target_dir, xml_path[:-3] + \"txt\"), \"w\") as file: # save labels\n",
    "        file.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff25d4",
   "metadata": {},
   "source": [
    "### Add images with no objects to our train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7abbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_images = os.listdir(\"empty_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9689ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in empty_images:\n",
    "    image = cv.imread(os.path.join(\"empty_images/\", image_name))\n",
    "    new_name = str(random.randint(5000, 9000)) + \".jpg\"\n",
    "    \n",
    "    cv.imwrite(os.path.join(train_images_target_dir, new_name), image)\n",
    "    \n",
    "    open(os.path.join(train_labels_target_dir, new_name[:-3] + \"txt\"), \"w\").close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44807e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
